{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0299ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm  # 可选进度条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "# ==== 输入输出路径 ====\n",
    "input_dir = \"../Data_Output/Train/\"\n",
    "output_dir = \"../Data_Preprocessing/Image/Bloch_STT_1e-3_100nm/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "csv_files = glob.glob(os.path.join(input_dir, \"bloch_STT_*_sweep*.csv\"))\n",
    "\n",
    "# ==== 帮助函数 ====\n",
    "def get_key_times(t_array):\n",
    "    t_start = t_array[0]\n",
    "    t_end = t_array[-1]\n",
    "    t_middle = t_array[np.abs(t_array - (t_start + t_end)/2).argmin()]\n",
    "    return [t_start, t_middle, t_end]\n",
    "\n",
    "# ==== 主循环 ====\n",
    "for file_path in csv_files:\n",
    "    print(f\"正在处理文件: {file_path}\")\n",
    "    match = re.search(r'bloch_STT_(\\d+e\\d+)_sweep\\d+\\.csv', file_path)\n",
    "    if not match:\n",
    "        print(f\"跳过无效文件名: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    jx_str = match.group(1)\n",
    "    jx_val = float(jx_str)\n",
    "\n",
    "    df = pd.read_csv(file_path, skiprows=8)\n",
    "    t_array = np.sort(df[\"t\"].unique())\n",
    "    if len(t_array) < 3:\n",
    "        continue\n",
    "\n",
    "    key_times = get_key_times(t_array)\n",
    "    num_cols = df.shape[1]\n",
    "    jx_frames = []\n",
    "\n",
    "    for t_val in key_times:\n",
    "        base_frame = df[df[\"t\"] == t_val][[\"% X\", \"Y\", \"t\"]].copy()\n",
    "\n",
    "        for col in range(3, num_cols, 5):\n",
    "            mX_col = df.columns[col]\n",
    "            mY_col = df.columns[col + 1]\n",
    "            mZ_col = df.columns[col + 2]\n",
    "            alpha_col = df.columns[col + 3]\n",
    "            beta_col = df.columns[col + 4]\n",
    "\n",
    "            alpha_val = df[alpha_col].iloc[0]\n",
    "            beta_val = df[beta_col].iloc[0]\n",
    "\n",
    "            suffix = f\"@ alpha={alpha_val}; beta={beta_val}\"\n",
    "\n",
    "            base_frame[f\"mX (1) {suffix}\"] = df[df[\"t\"] == t_val][mX_col].values\n",
    "            base_frame[f\"mY (1) {suffix}\"] = df[df[\"t\"] == t_val][mY_col].values\n",
    "            base_frame[f\"mZ (1) {suffix}\"] = df[df[\"t\"] == t_val][mZ_col].values\n",
    "\n",
    "        jx_frames.append(base_frame)\n",
    "\n",
    "    if jx_frames:\n",
    "        jx_df = pd.concat(jx_frames, axis=0)\n",
    "        output_path = os.path.join(output_dir, f\"skx_3frames_jx={jx_str}.csv\")\n",
    "        jx_df.to_csv(output_path, index=False)\n",
    "        print(f\"✅ 已保存: {output_path}（{len(jx_df)} 行）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d33eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "# ==== 路径配置 ====\n",
    "input_dir = \"../Data_Output/Train/\"\n",
    "output_dir = \"../Data_Preprocessing/Preprocessed_Dataset/jx_separated/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_files = glob.glob(os.path.join(input_dir, \"bloch_STT_*_sweep*.csv\"))\n",
    "\n",
    "# ==== 获取关键时间帧 ====\n",
    "def get_key_times(t_array):\n",
    "    t_start = t_array[0]\n",
    "    t_end = t_array[-1]\n",
    "    t_middle = t_array[np.abs(t_array - (t_start + t_end) / 2).argmin()]\n",
    "    return [t_start, t_middle, t_end]\n",
    "\n",
    "# ==== 主循环 ====\n",
    "for file_path in csv_files:\n",
    "    match = re.search(r'bloch_STT_(\\d+e\\d+)_sweep\\d+\\.csv', file_path)\n",
    "    if not match:\n",
    "        print(f\"跳过无效文件名: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    jx_str = match.group(1)\n",
    "    jx_val = float(jx_str)\n",
    "\n",
    "    print(f\"\\n▶️ 正在处理文件: {file_path}\")\n",
    "    df = pd.read_csv(file_path, skiprows=8)\n",
    "    t_array = np.sort(df[\"t\"].unique())\n",
    "    if len(t_array) < 3:\n",
    "        print(f\"⏭️ 跳过：时间帧不足3个\")\n",
    "        continue\n",
    "\n",
    "    key_times = get_key_times(t_array)\n",
    "    num_cols = df.shape[1]\n",
    "    jx_frames = []\n",
    "\n",
    "    for t_val in key_times:\n",
    "        df_frame = df[df[\"t\"] == t_val]\n",
    "        if df_frame.empty:\n",
    "            continue\n",
    "\n",
    "        base = df_frame[[\"% X\", \"Y\", \"t\"]].reset_index(drop=True)\n",
    "        all_magnetics = []\n",
    "\n",
    "        for col in range(3, num_cols, 5):\n",
    "            mX_col = df.columns[col]\n",
    "            mY_col = df.columns[col + 1]\n",
    "            mZ_col = df.columns[col + 2]\n",
    "            alpha_col = df.columns[col + 3]\n",
    "            beta_col = df.columns[col + 4]\n",
    "\n",
    "            alpha_val = df[alpha_col].iloc[0]\n",
    "            beta_val = df[beta_col].iloc[0]\n",
    "\n",
    "            suffix = f\"@ alpha={alpha_val}; beta={beta_val}\"\n",
    "\n",
    "            # 一次性添加列（避免 insert 多次触发碎片化）\n",
    "            group = pd.DataFrame({\n",
    "                f\"mX (1) {suffix}\": df_frame[mX_col].values,\n",
    "                f\"mY (1) {suffix}\": df_frame[mY_col].values,\n",
    "                f\"mZ (1) {suffix}\": df_frame[mZ_col].values\n",
    "            })\n",
    "\n",
    "            all_magnetics.append(group)\n",
    "\n",
    "        # 合并 base + 所有磁化向量列\n",
    "        frame_all = pd.concat([base] + all_magnetics, axis=1)\n",
    "        jx_frames.append(frame_all)\n",
    "\n",
    "    # 保存每个 jx 为单独 CSV\n",
    "    if jx_frames:\n",
    "        jx_df = pd.concat(jx_frames, axis=0)\n",
    "        output_path = os.path.join(output_dir, f\"skx_3frames_jx={jx_str}.csv\")\n",
    "        jx_df.to_csv(output_path, index=False)\n",
    "        print(f\"✅ 已保存到: {output_path}，共 {len(jx_df)} 行\")\n",
    "    else:\n",
    "        print(f\"⚠️ 没有有效帧可写入：{file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
